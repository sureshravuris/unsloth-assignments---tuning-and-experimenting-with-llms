# Unsloth-assignments---tuning-and-experimenting-with-llms


## Assignment Descriptions
### Part A - Finetuning
### Description:
You will finetune with following open weights llm modules.
You will clearly explain in video how this works, what are the input format and data set used etc.,. very clearly for one variety of task per model - coding, chat etc.,.
Do four unique usecases - you will use various chat model templates.

## Part B - LLM Learn New Language
### Description:
Use unsloth ai to make llm learn a new language.

## Part C - Chat Templates
### Description:
Create a colab showcasing chat templates for the following:

- Classification
- Conversational Chat
- Extending Max Context Size of Tinyllama
- Multiple Data Sets (Single Finetuning)
  
## Part D - Reward Modeling with ORPO and DPO
### Description:
Do reward modeling colab with ORPO and colab with DPO.

## Part E - Continued Fine Tuning
### Description:
Do continued fine tuning from custom checkpoint usecase.

## Part F - Finetuning for Mental Health Development Chatbot
### Description:
Finetune unsloth for a mental health development chatbot.

## Part G - Finetune and export to Ollama
### Description:
Use unsloth to finetune a model and export to ollama. Be sure to show inference.
